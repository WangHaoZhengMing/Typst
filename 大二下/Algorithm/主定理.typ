#set text(font: "PingFang SC")
#import "@preview/cetz:0.3.4": *
#import "@preview/cetz-plot:0.1.0": *
#import "@preview/showybox:2.0.4": showybox

= 主定理 (Master Theorem) 详解

主定理是分析分治算法时间复杂度的有力工具。它提供了一个"菜谱式"的方法，用于求解形如 $T(n) = a T(n/b) + f(n)$ 的递推关系式，其中 $n$ 是问题规模，$a$ 是递归子问题的数量，$n/b$ 是每个子问题的规模（假设 $n$ 是 $b$ 的幂，或者考虑 $floor$ 或 $ceil$），$f(n)$ 是在划分问题和合并结果时需要完成的工作量。
#figure(caption: [递归分解示意图])[
  #canvas({
    import draw: *
    // 第一层（原问题）
    rect((-6, 0), (6, 1), stroke: black)
    content((0, 0.5), [$n$ 原问题规模])

    // 箭头连接
    line((0, -0.2), (0, -1), mark: (end: ">"))

    // 第二层（子问题）
    let width = 3
    for i in range(-2, 3, step: 2) {
      rect((i - width / 2, -2), (i + width / 2, -1), stroke: black)
      content((i, -1.5), [$n / b$])
    }

    // 省略号表示可能有更多子问题
    content((-4.5, -1.5), [...])
    content((4.5, -1.5), [...])

    // 标注
    // content((1.5, 0.5), [原问题规模])
    content((0, -2.5), [$a$ 个子问题])
  })
]

== 什么是主定理?

考虑递推关系式：
$ T(n) = a T(n / b) + f(n) $
其中：
- $a >= 1$: 每次递归调用产生的子问题数量。
- $b > 1$: 每个子问题的规模相对于原问题的缩小因子。
- $f(n)$: 每次递归调用中，除了递归本身之外的额外工作量（例如，划分问题、合并子问题的结果）。要求 $f(n)$ 是渐进正函数 (asymptotically positive)。

主定理通过比较函数 $f(n)$ 和 $n^(log_b a)$ 的增长率，给出了 $T(n)$ 的渐进界。

== 主定理是如何得到的 (推导思路)?

主定理的推导通常依赖于 *递归树* (Recursion Tree) 的方法。让我们想象一下递归调用的过程：

1. *根节点*: 代表原始问题 $T(n)$，在本层产生的非递归成本是 $f(n)$。
2. *第一层*: 根节点产生 $a$ 个子问题，每个子问题的规模是 $n/b$。这一层的总非递归成本是 $a times f(n/b)$。
3. *第二层*: 每个第一层的节点又产生 $a$ 个子问题，总共 $a^2$ 个子问题，每个规模是 $n/b^2$。这一层的总非递归成本是 $a^2 times f(n/b^2)$。
4. *第 k 层*: 总共有 $a^k$ 个子问题，每个规模是 $n/b^k$。这一层的总非递归成本是 $a^k times f(n/b^k)$。
5. *叶子节点*: 递归持续进行，直到问题规模变为常数（比如 $n=1$）。这发生在第 $k$ 层，其中#box(stroke: 1pt, inset: 3pt, baseline: 3pt)[$n/b^k approx 1$, 即 $k approx log_b n$]。叶子节点的数量是 $a^k = a^(log_b n) = n^(log_b a)$ (根据对数换底公式 $a^(log_b n) = n^(log_b a)$)。假设 $T(1) = Theta(1)$，那么所有叶子节点的总成本是 $Theta(n^(log_b a))$。

现在，总的时间复杂度 $T(n)$ 是树中所有节点成本的总和：
$ T(n) = sum_(k=0)^(log_b (n - 1)) a^k f(n / b^k) + Theta(n^(log_b a)) $

主定理的核心思想是比较 *根节点的成本* ($f(n)$) 和 *所有叶子节点的总成本* ($Theta(n^(log_b a))$) 的相对增长速度。这决定了总成本主要由哪部分贡献：
- 如果叶子节点的成本 *渐进地* 大于任何一层内部节点的成本（特别是根节点），那么总成本由叶子节点决定 (情况 1)。#sym.triangle.filled.b
- 如果每一层的成本大致相当，那么总成本是 (每层成本) $times$ (层数) (情况 2)。#sym.dot.square
- 如果根节点的成本 *渐进地* 大于下面所有层级的成本之和，那么总成本由根节点决定 (情况 3)。#sym.triangle.filled 

这三种情况就构成了主定理的三个分支。

== 主定理的内容 (三个核心情况)

令 $c_"crit" = log_b a$。我们比较 $f(n)$ 和 $n^(c_"crit")$ 的渐进增长。

#showybox(
  title: [主定理 (Master Theorem)],
  frame: (
    dash: "dashed",
  ),
)[
  设 $T(n) = a T(n/b) + f(n)$，其中 $a >= 1, b > 1$，$f(n)$ 渐进正。令 $c_"crit" = log_b a$。

  *情况 1:*#sym.triangle.filled \
  如果存在常数 $epsilon > 0$，使得 $f(n) = O(n^(c_"crit" - epsilon))$，则：
  $ T(n) = Theta(n^(c_"crit")) = Theta(n^(log_b a)) $
  #emph[直观理解：叶子节点的成本占主导地位。]

  *情况 2:*#sym.dot.square \
  如果存在常数 $k >= 0$，使得 $f(n) = Theta(n^(c_"crit") log^k n)$，则：
  $ T(n) = Theta(n^(c_"crit") log^(k+1) n) $

  特别地，如果 $f(n) = Theta(n^(c_"crit"))$ (即 $k=0$)，则：
  $ T(n) = Theta(n^(c_"crit") log n) = Theta(n^(log_b a) log n) $
  #emph[直观理解：成本在递归树的各层级之间大致平衡，总成本是每层成本乘以层数 (对数因子)。]

  *情况 3:*#sym.triangle.filled.b \
  如果存在常数 $epsilon > 0$，使得 $f(n) = Omega(n^(c_"crit" + epsilon))$，*并且* 存在常数 $c < 1$ 和足够大的 $n$，使得 $a f(n/b) <= c f(n)$ (*正则性条件*)，则：
  $ T(n) = Theta(f(n)) $
  #emph[直观理解：根节点 (或靠近根的几层) 的成本占主导地位。正则性条件确保成本不会在较低层级意外地"爆炸"从而超过根成本。]
]

#emph[注意]:
- 三种情况之间存在*间隙*。例如，$display(f(n) = n^(c_"crit") / (log n))$ 就不属于上述任何一种情况。此时不能直接使用主定理（可能需要更高级的 Akra-Bazzi 定理）。
- 情况 1 和 情况 3 要求 $f(n)$ 与 $n^(c_"crit")$ 之间存在*多项式*差异（由 $epsilon$ 体现）。
- 情况 3 的*正则性条件* ($a f(n/b) <= c f(n)$ for some $c<1$) 是必需的，虽然对于很多常见的 $f(n)$（如多项式函数）是自动满足的。例如，如果 $f(n) = n^k$，则 $a (n/b)^k = (a/b^k) n^k$。要满足正则性条件，需要 $a/b^k < 1$，即 $a < b^k$，等价于 $log_b a < k$。这与情况 3 的主要条件 $f(n) = n^k = Omega(n^(log_b a + epsilon))$ 一致。

== 如何使用主定理 (应用步骤与示例)?

使用主定理的步骤非常直接：

1. *识别参数*: 从给定的递推式 $T(n) = a T(n/b) + f(n)$ 中，确定 $a$, $b$, 和 $f(n)$。确保 $a >= 1$, $b > 1$。
2. *计算临界指数*: 计算 $c_"crit" = log_b a$。
3. *比较增长率*: 比较 $f(n)$ 和 $n^(c_"crit")$ 的渐进增长率。
4. *匹配情况*:
  - 如果 $f(n)$ 渐进地 (多项式地) *慢于* $n^(c_"crit")$，则应用情况 1。
  - 如果 $f(n)$ 渐进地 *等于* $n^(c_"crit") log^k n$ (对于某个 $k >= 0$)，则应用情况 2。
  - 如果 $f(n)$ 渐进地 (多项式地) *快于* $n^(c_"crit")$，并且满足*正则性条件*，则应用情况 3。
5. *得出结论*: 根据匹配的情况，写出 $T(n)$ 的渐进界。

#line(length: 100%, stroke: 0.5pt)
*示例 1: 归并排序 (Merge Sort)*
递推式: $T(n) = 2 T(n/2) + Theta(n)$
1. $a = 2$, $b = 2$, $f(n) = Theta(n)$
2. $c_"crit" = log_2 2 = 1$
3. 比较 $f(n) = Theta(n)$ 和 $n^(c_"crit") = n^1 = n$。它们是相同的。
4. 匹配情况 2 (其中 $k=0$, 因为 $f(n) = Theta(n^1 log^0 n)$)。
5. 结论: $T(n) = Theta(n^(c_"crit") log^(0+1) n) = Theta(n^1 log n) = Theta(n log n)$。

#line(length: 100%, stroke: 0.5pt)
*示例 2: 二分查找 (Binary Search) 的递归形式*
递推式: $T(n) = 1 T(n/2) + Theta(1)$
1. $a = 1$, $b = 2$, $f(n) = Theta(1)$
2. $c_"crit" = log_2 1 = 0$
3. 比较 $f(n) = Theta(1)$ 和 $n^(c_"crit") = n^0 = 1$。它们是相同的。
4. 匹配情况 2 (其中 $k=0$, 因为 $f(n) = Theta(n^0 log^0 n)$)。
5. 结论: $T(n) = Theta(n^(c_"crit") log^(0+1) n) = Theta(n^0 log n) = Theta(log n)$。

#line(length: 100%, stroke: 0.5pt)
*示例 3: Strassen 矩阵乘法*
递推式: $T(n) = 7 T(n/2) + Theta(n^2)$
1. $a = 7$, $b = 2$, $f(n) = Theta(n^2)$
2. $c_"crit" = log_2 7 approx 2.81$
3. 比较 $f(n) = Theta(n^2)$ 和 $n^(c_"crit") = n^(log_2 7)$。因为 $2 < log_2 7$, 所以 $f(n)$ 增长慢于 $n^(c_"crit")$。
4. 检查情况 1: 我们需要 $f(n) = O(n^(c_"crit" - epsilon))$。令 $epsilon = log_2 7 - 2 > 0$。那么 $n^(c_"crit" - epsilon) = n^(log_2 7 - (log_2 7 - 2)) = n^2$。确实 $f(n) = Theta(n^2) = O(n^2)$。所以情况 1 适用。
5. 结论: $T(n) = Theta(n^(c_"crit")) = Theta(n^(log_2 7))$。

#line(length: 100%, stroke: 0.5pt)
*示例 4: 一个更复杂的例子*
递推式: $T(n) = 3 T(n/4) + n log n$
1. $a = 3$, $b = 4$, $f(n) = n log n$
2. $c_"crit" = log_4 3 approx 0.79$
3. 比较 $f(n) = n log n$ 和 $n^(c_"crit") = n^(log_4 3)$。因为 $1 > log_4 3$, 且 $log n$ 因子使得 $n log n$ 增长快于任何 $n^p$ 其中 $p<1$, 所以 $f(n)$ 增长快于 $n^(c_"crit")$。
4. 检查情况 3:
  - 主要条件: 需要 $f(n) = Omega(n^(c_"crit" + epsilon))$。令 $epsilon = 1 - log_4 3 > 0$。我们需要 $n log n = Omega(n^(log_4 3 + (1 - log_4 3))) = Omega(n^1)$。这是成立的，因为 $log n$ 渐进增长。
  - 正则性条件: 需要 $a f(n/b) <= c f(n)$ for some $c < 1$。即 $3 * (n/4) log(n/4) <= c * n log n$。
    $3 / 4 * n (log n - log 4) <= c * n log n$
    $3 / 4 * (1 - (log 4) / (log n)) <= c$
    当 $n -> infinity$, $(log 4) / (log n) -> 0$。所以左边趋近于 $3/4$。我们可以选择 $c$ 使得 $3/4 < c < 1$ (例如 $c=0.8$)。正则性条件满足。
5. 结论: $T(n) = Theta(f(n)) = Theta(n log n)$。

== 类比: 公司扩张

想象一下你需要管理一个大型项目（问题规模 $n$），你需要投入的总精力是 $T(n)$。

- *分治策略*: 你决定将这个大项目分解成 $a$ 个结构相同、规模更小的子项目，每个子项目的规模是原来的 $1/b$（对应 $a T(n/b)$）。
- *管理/整合成本*: 在你这一层级，你需要花费精力 $f(n)$ 来进行任务分解、协调子项目、以及最后整合子项目的成果。
- *基础工作潜力*: $n^(log_b a)$ 可以理解为，如果所有工作最终都归结为最底层的、不可再分的小任务，那么所有这些小任务汇集起来的总工作量潜力。它反映了子项目数量 $a$ 和规模缩小因子 $b$ 之间的关系。

现在来看主定理的三个情况：

1. *情况 1: $f(n)$ 远小于 $n^(log_b a)$*
  *   *类比*: 每一层的管理和整合成本 ($f(n)$) 相比于最终底层执行团队的总工作潜力 ($n^(log_b a)$) 来说微不足道。就像一个金字塔结构，虽然层级很多，但绝大部分实际工作量都在最底层。
    * *结果*: 总精力主要由底层庞大的基础任务量决定，$T(n) = Theta(n^(log_b a))$。

2. *情况 2: $f(n)$ 与 $n^(log_b a)$ 相当*
  *   *类比*: 每一层的管理/整合成本 ($f(n)$) 与该层级对应的基础工作潜力 ($n^(c_"crit")$) 大致相当 (可能差个 $log^k n$ 因子)。这意味着工作量比较均匀地分布在公司的各个层级上。
    * *结果*: 总精力是基础工作潜力 $n^(log_b a)$ 乘以层级的数量 (约为 $log n$)。$T(n) = Theta(n^(log_b a) log^(k+1) n)$。

3. *情况 3: $f(n)$ 远大于 $n^(log_b a)$ (且满足正则性)*
  *   *类比*: 最高层的管理、协调和整合成本 ($f(n)$) 非常高昂，它本身就超过了下面所有子项目及其管理成本的总和。就像一个项目，初期的规划和最终的集成工作极其复杂，远超中间分解执行的部分。正则性条件确保了下层的成本不会反常地增长以至于超过顶层。
    * *结果*: 总精力主要由最高层的成本决定，$T(n) = Theta(f(n))$。

== 注意事项与局限性

- 主定理只适用于特定形式 $T(n) = a T(n/b) + f(n)$ 的递推关系。
- $a$ 和 $b$ 必须是常数，$a >= 1, b > 1$。
- $n/b$ 通常指 $floor(n/b)$ 或 $ceil(n/b)$，主定理对这两种情况都适用。
- 如前所述，主定理的三个情况并未覆盖所有可能的 $f(n)$。存在一些函数 $f(n)$ 使得递推关系无法用主定理解决。
- 理解渐进符号 ($O, Omega, Theta$) 和对数性质对于正确应用主定理至关重要。

== 总结

主定理是一个强大且方便的工具，用于求解许多常见分治算法的时间复杂度。其核心在于比较问题分解/合并的成本 $f(n)$ 与由子问题数量 $a$ 和规模缩小因子 $b$ 决定的临界函数 $n^(log_b a)$ 的增长率。通过确定 $f(n)$ 落入三个情况中的哪一个，我们可以快速得到 $T(n)$ 的渐进复杂度。熟练掌握主定理对于算法分析非常有帮助。


$ integral_(-oo)^a x^2 d x $